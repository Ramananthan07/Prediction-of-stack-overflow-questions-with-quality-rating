{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f797f042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-for-tf2 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.14.9)\n",
      "Requirement already satisfied: py-params>=0.9.6 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-for-tf2) (0.10.2)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.61.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
      "Requirement already satisfied: transformers in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: requests in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.61.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2\n",
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50569c1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import bert\n",
    "import math\n",
    "import re as re\n",
    "import transformers\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05a5e045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id                                             Title  \\\n",
      "0  34555135                                 Pandas: read_html   \n",
      "1  34557209  How do I make a constructor for a derived class?   \n",
      "2  34557587               Re-exporting ES6 modules in TS 1.7?   \n",
      "3  34558264                             Fetch API with Cookie   \n",
      "4  34559136               Print list content in a given order   \n",
      "\n",
      "                                                Body  \\\n",
      "0  <p>I'm trying to extract US states from wiki U...   \n",
      "1  <p>I am trying to make a constructor for a der...   \n",
      "2  <p>I'm getting a bit lost in TS re-exports. Sa...   \n",
      "3  <p>I am trying out the new Fetch API but is ha...   \n",
      "4  <pre><code>lt = ['7,777.7', '777.7', '77,777.7...   \n",
      "\n",
      "                                                Tags    CreationDate   Y  \n",
      "0                                   <python><pandas>   1/1/2016 9:55  HQ  \n",
      "1     <c++><inheritance><constructor><derived-class>  1/1/2016 14:58  LQ  \n",
      "2  <typescript><ecmascript-6><es6-module-loader><...  1/1/2016 15:50  HQ  \n",
      "3                               <cookies><fetch-api>  1/1/2016 17:21  HQ  \n",
      "4               <python><list><python-2.7><for-loop>  1/1/2016 19:08  LQ  \n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"C:/Users/Ai.localadmin/Desktop/text-clas/data.csv\")\n",
    "print(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "802e7b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LQ', 'HQ'}\n",
      "Number of qualities:  2\n"
     ]
    }
   ],
   "source": [
    "print(set(all_data['Y']))\n",
    "print('Number of qualities: ',len(set(all_data['Y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8307ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_data[(all_data['Y']=='LQ') | (all_data['Y']=='HQ')].copy()\n",
    "data.index = [i for i in range(data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ce0ceac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1655, 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1fd0654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Body', 'Tags', 'CreationDate', 'Y'], dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed7bd3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               int64\n",
       "Title           object\n",
       "Body            object\n",
       "Tags            object\n",
       "CreationDate    object\n",
       "Y               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4ec11dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              0\n",
       "Title           0\n",
       "Body            0\n",
       "Tags            0\n",
       "CreationDate    0\n",
       "Y               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f204aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Y'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eeee1290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34555135</td>\n",
       "      <td>Pandas: read_html</td>\n",
       "      <td>&lt;p&gt;I'm trying to extract US states from wiki U...</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;</td>\n",
       "      <td>1/1/2016 9:55</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34557209</td>\n",
       "      <td>How do I make a constructor for a derived class?</td>\n",
       "      <td>&lt;p&gt;I am trying to make a constructor for a der...</td>\n",
       "      <td>&lt;c++&gt;&lt;inheritance&gt;&lt;constructor&gt;&lt;derived-class&gt;</td>\n",
       "      <td>1/1/2016 14:58</td>\n",
       "      <td>LQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34557587</td>\n",
       "      <td>Re-exporting ES6 modules in TS 1.7?</td>\n",
       "      <td>&lt;p&gt;I'm getting a bit lost in TS re-exports. Sa...</td>\n",
       "      <td>&lt;typescript&gt;&lt;ecmascript-6&gt;&lt;es6-module-loader&gt;&lt;...</td>\n",
       "      <td>1/1/2016 15:50</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34558264</td>\n",
       "      <td>Fetch API with Cookie</td>\n",
       "      <td>&lt;p&gt;I am trying out the new Fetch API but is ha...</td>\n",
       "      <td>&lt;cookies&gt;&lt;fetch-api&gt;</td>\n",
       "      <td>1/1/2016 17:21</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34559136</td>\n",
       "      <td>Print list content in a given order</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;lt = ['7,777.7', '777.7', '77,777.7...</td>\n",
       "      <td>&lt;python&gt;&lt;list&gt;&lt;python-2.7&gt;&lt;for-loop&gt;</td>\n",
       "      <td>1/1/2016 19:08</td>\n",
       "      <td>LQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                             Title  \\\n",
       "0  34555135                                 Pandas: read_html   \n",
       "1  34557209  How do I make a constructor for a derived class?   \n",
       "2  34557587               Re-exporting ES6 modules in TS 1.7?   \n",
       "3  34558264                             Fetch API with Cookie   \n",
       "4  34559136               Print list content in a given order   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'm trying to extract US states from wiki U...   \n",
       "1  <p>I am trying to make a constructor for a der...   \n",
       "2  <p>I'm getting a bit lost in TS re-exports. Sa...   \n",
       "3  <p>I am trying out the new Fetch API but is ha...   \n",
       "4  <pre><code>lt = ['7,777.7', '777.7', '77,777.7...   \n",
       "\n",
       "                                                Tags    CreationDate   Y  \n",
       "0                                   <python><pandas>   1/1/2016 9:55  HQ  \n",
       "1     <c++><inheritance><constructor><derived-class>  1/1/2016 14:58  LQ  \n",
       "2  <typescript><ecmascript-6><es6-module-loader><...  1/1/2016 15:50  HQ  \n",
       "3                               <cookies><fetch-api>  1/1/2016 17:21  HQ  \n",
       "4               <python><list><python-2.7><for-loop>  1/1/2016 19:08  LQ  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "643ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['information'] = data[['Title','Body']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42da2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"categoryEncoded\"] = label_encoder.fit_transform(data['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64c5313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ai.localadmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ai.localadmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text,stem=False):\n",
    "    # Lower case\n",
    "    text = text.lower().strip()\n",
    "    # Removing html tags\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    # Remove punctuations and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Single character removal\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    # Removing multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Removing stop words\n",
    "    text =  [word.lower() for word in text.split() if word not in stopwords.words('english')]\n",
    "    # lemmatize data\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    text = [stemmer.lemmatize(word) for word in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e1adb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the text data\n",
    "L = []\n",
    "sentences = list(data['information'])\n",
    "for sen in sentences:\n",
    "    L.append(preprocess_text(sen))\n",
    "\n",
    "# save the result\n",
    "open_file = open(\"text_preprocessed\", \"wb\")\n",
    "pickle.dump(L, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "97d05337",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49ac7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27f41f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reviews(text_reviews):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))\n",
    "\n",
    "tokenized_data = [tokenize_reviews(d) for d in data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00411a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [[x,data['categoryEncoded'][i]] for i, x in enumerate(tokenized_data)]\n",
    "random.shuffle(data_list)\n",
    "shuffled_data = [(x[0], x[1]) for x in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bedeb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sorted dataset into a TensorFlow 2.0-compliant input dataset shape.\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: shuffled_data, output_types=(tf.int32, tf.int32))\n",
    "\n",
    "#  pad the dataset for each batch\n",
    "categories = 6\n",
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "\n",
    "# We divide the dataset into test and training sets\n",
    "TOTAL_BATCHES = math.ceil(len(shuffled_data) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8467480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "\n",
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        #self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,kernel_size=4,padding=\"valid\",activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        #l_3 = self.cnn_layer3(l)\n",
    "        #l_3 = self.pool(l_3) \n",
    "        \n",
    "        #concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = tf.concat([l_1, l_2], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d790606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyper parameters\n",
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = categories\n",
    "DROPOUT_RATE = 0.2\n",
    "NB_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d10e5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a7cbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie the model\n",
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "579a9be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "47/47 [==============================] - 14s 287ms/step - loss: 0.8814 - sparse_categorical_accuracy: 0.5338 - val_loss: 0.6602 - val_sparse_categorical_accuracy: 0.5437\n",
      "Epoch 2/2\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.5007 - sparse_categorical_accuracy: 0.7826 - val_loss: 0.5104 - val_sparse_categorical_accuracy: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2372353b8b0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "text_model.fit(train_data, batch_size=BATCH_SIZE,epochs=NB_EPOCHS, validation_data=(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6bbe4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 79ms/step - loss: 0.5104 - sparse_categorical_accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "\n",
    "results = text_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c23f6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorize = TfidfVectorizer()\n",
    "tf_idf_text = vectorize.fit(data['text'])\n",
    "vector1 = tf_idf_text.transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5fee3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(vector1, data['Y'], test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dfca738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix\n",
    "\n",
    "SVM = LinearSVC()\n",
    "SVM.fit(X_train,Y_train)\n",
    "Y_predict = SVM.predict(X_test)\n",
    "accuracy_SVM = accuracy_score(Y_test,Y_predict)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84334c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_Regression = LogisticRegression()\n",
    "logistic_Regression.fit(X_train,Y_train)\n",
    "Y_predict = logistic_Regression.predict(X_test)\n",
    "accuracy_logistic_Regression = accuracy_score(Y_test,Y_predict)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d188538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NaiveBayes = MultinomialNB(alpha=0.1)\n",
    "NaiveBayes.fit(X_train,Y_train)\n",
    "Y_predict = NaiveBayes.predict(X_test)\n",
    "accuracy_NaiveBayes = accuracy_score(Y_test,Y_predict)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0d8668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "\n",
      "CNN + Bert:  78.12 %\n",
      "SVM:  78.43 %\n",
      "Logistic Regression:  77.33 %\n",
      "Naive Bayes:  76.78 %\n"
     ]
    }
   ],
   "source": [
    "# Diplaying accuracy for each model\n",
    "\n",
    "print(\"Accuracy\\n\")\n",
    "print(\"CNN + Bert: \", format(results[1]*100, '.2f'),\"%\")\n",
    "print(\"SVM: \",format(accuracy_SVM, '.2f'),\"%\")\n",
    "print(\"Logistic Regression: \",format(accuracy_logistic_Regression, '.2f'),\"%\")\n",
    "print(\"Naive Bayes: \",format(accuracy_NaiveBayes, '.2f'),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a95d690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categories\n",
    "\n",
    "catego = ['LQ', 'HQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7668c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test text\n",
    "\n",
    "text = \"Fetch API with Cookie\"\n",
    "text = \"Form Validation project\" \n",
    "text = \"Django ImageField upload_to path\"\n",
    "t = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "81515ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN + Bert:  LQ\n",
      "SVM:  ['HQ']\n",
      "Logistic Regression:  ['HQ']\n",
      "Naive Bayes:  ['HQ']\n"
     ]
    }
   ],
   "source": [
    "prediction = text_model.predict([tokenize_reviews(t)])\n",
    "print(\"CNN + Bert: \",catego[np.argmax(prediction)])\n",
    "print(\"SVM: \",SVM.predict(tf_idf_text.transform([t])))\n",
    "print(\"Logistic Regression: \",logistic_Regression.predict(tf_idf_text.transform([t])))\n",
    "print(\"Naive Bayes: \",NaiveBayes.predict(tf_idf_text.transform([t])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b962cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "# saving the model\n",
    "\n",
    "text_model.save('model',save_format='tf')\n",
    "#!apt-get install rar\n",
    "#!zip -r \"model.zip\" \"/content/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "144e786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ai.localadmin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(n_components=6, random_state=42)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(n_components=categories,random_state=42)\n",
    "nmf_model.fit(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f7442d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 10 WORDS FOR TOPIC #0\n",
      "['php', 'form', 'id', 'td', 'class', 'html', 'name', 'div', 'gt', 'lt']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #1\n",
      "['function', 'request', 'get', 'like', 'want', 'use', 'using', 'app', 'data', 'user']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #2\n",
      "['include', 'number', 'return', 'main', 'amp', 'printf', 'function', 'value', 'array', 'int']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #3\n",
      "['button', 'studio', 'activity', 'dp', 'support', 'com', 'app', 'java', 'layout', 'android']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #4\n",
      "['package', 'java', 'directory', 'path', 'image', 'folder', 'txt', 'line', 'python', 'file']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #5\n",
      "['static', 'system', 'java', 'regex', 'character', 'list', 'number', 'public', 'date', 'string']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP 10 WORDS FOR TOPIC #{index}')\n",
    "    print([tf_idf_text.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d2d4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = nmf_model.transform(vector1)\n",
    "topic_results.argmax(axis=1)\n",
    "\n",
    "data['NMF'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b1604f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "      <th>information</th>\n",
       "      <th>categoryEncoded</th>\n",
       "      <th>text</th>\n",
       "      <th>NMF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34555135</td>\n",
       "      <td>Pandas: read_html</td>\n",
       "      <td>&lt;p&gt;I'm trying to extract US states from wiki U...</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;</td>\n",
       "      <td>1/1/2016 9:55</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Pandas: read_html &lt;p&gt;I'm trying to extract US ...</td>\n",
       "      <td>0</td>\n",
       "      <td>panda read html trying extract u state wiki ur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34557209</td>\n",
       "      <td>How do I make a constructor for a derived class?</td>\n",
       "      <td>&lt;p&gt;I am trying to make a constructor for a der...</td>\n",
       "      <td>&lt;c++&gt;&lt;inheritance&gt;&lt;constructor&gt;&lt;derived-class&gt;</td>\n",
       "      <td>1/1/2016 14:58</td>\n",
       "      <td>LQ</td>\n",
       "      <td>How do I make a constructor for a derived clas...</td>\n",
       "      <td>1</td>\n",
       "      <td>make constructor derived class trying make con...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34557587</td>\n",
       "      <td>Re-exporting ES6 modules in TS 1.7?</td>\n",
       "      <td>&lt;p&gt;I'm getting a bit lost in TS re-exports. Sa...</td>\n",
       "      <td>&lt;typescript&gt;&lt;ecmascript-6&gt;&lt;es6-module-loader&gt;&lt;...</td>\n",
       "      <td>1/1/2016 15:50</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Re-exporting ES6 modules in TS 1.7? &lt;p&gt;I'm get...</td>\n",
       "      <td>0</td>\n",
       "      <td>exporting e module t getting bit lost t export...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34558264</td>\n",
       "      <td>Fetch API with Cookie</td>\n",
       "      <td>&lt;p&gt;I am trying out the new Fetch API but is ha...</td>\n",
       "      <td>&lt;cookies&gt;&lt;fetch-api&gt;</td>\n",
       "      <td>1/1/2016 17:21</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Fetch API with Cookie &lt;p&gt;I am trying out the n...</td>\n",
       "      <td>0</td>\n",
       "      <td>fetch api cookie trying new fetch api trouble ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34559136</td>\n",
       "      <td>Print list content in a given order</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;lt = ['7,777.7', '777.7', '77,777.7...</td>\n",
       "      <td>&lt;python&gt;&lt;list&gt;&lt;python-2.7&gt;&lt;for-loop&gt;</td>\n",
       "      <td>1/1/2016 19:08</td>\n",
       "      <td>LQ</td>\n",
       "      <td>Print list content in a given order &lt;pre&gt;&lt;code...</td>\n",
       "      <td>1</td>\n",
       "      <td>print list content given order lt proceed prin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                             Title  \\\n",
       "0  34555135                                 Pandas: read_html   \n",
       "1  34557209  How do I make a constructor for a derived class?   \n",
       "2  34557587               Re-exporting ES6 modules in TS 1.7?   \n",
       "3  34558264                             Fetch API with Cookie   \n",
       "4  34559136               Print list content in a given order   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'm trying to extract US states from wiki U...   \n",
       "1  <p>I am trying to make a constructor for a der...   \n",
       "2  <p>I'm getting a bit lost in TS re-exports. Sa...   \n",
       "3  <p>I am trying out the new Fetch API but is ha...   \n",
       "4  <pre><code>lt = ['7,777.7', '777.7', '77,777.7...   \n",
       "\n",
       "                                                Tags    CreationDate   Y  \\\n",
       "0                                   <python><pandas>   1/1/2016 9:55  HQ   \n",
       "1     <c++><inheritance><constructor><derived-class>  1/1/2016 14:58  LQ   \n",
       "2  <typescript><ecmascript-6><es6-module-loader><...  1/1/2016 15:50  HQ   \n",
       "3                               <cookies><fetch-api>  1/1/2016 17:21  HQ   \n",
       "4               <python><list><python-2.7><for-loop>  1/1/2016 19:08  LQ   \n",
       "\n",
       "                                         information  categoryEncoded  \\\n",
       "0  Pandas: read_html <p>I'm trying to extract US ...                0   \n",
       "1  How do I make a constructor for a derived clas...                1   \n",
       "2  Re-exporting ES6 modules in TS 1.7? <p>I'm get...                0   \n",
       "3  Fetch API with Cookie <p>I am trying out the n...                0   \n",
       "4  Print list content in a given order <pre><code...                1   \n",
       "\n",
       "                                                text  NMF  \n",
       "0  panda read html trying extract u state wiki ur...    1  \n",
       "1  make constructor derived class trying make con...    2  \n",
       "2  exporting e module t getting bit lost t export...    1  \n",
       "3  fetch api cookie trying new fetch api trouble ...    1  \n",
       "4  print list content given order lt proceed prin...    5  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f877f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = cv.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d81c10ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=6, random_state=42)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=categories,random_state=42)\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2828bab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 10 WORDS FOR TOPIC #0\n",
      "['want', 'php', 'post', 'date', 'like', 'data', 'request', 'using', 'id', 'user']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #1\n",
      "['org', 'button', 'com', 'div', 'id', 'class', 'java', 'android', 'lt', 'gt']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #2\n",
      "['int', 'gt', 'lt', 'new', 'var', 'return', 'public', 'amp', 'function', 'string']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #3\n",
      "['code', 'import', 'file', 'like', 'want', 'use', 'error', 'component', 'using', 'app']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #4\n",
      "['result', 'type', 'code', 'input', 'gt', 'print', 'value', 'array', 'number', 'int']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #5\n",
      "['module', 'line', 'run', 'error', 'image', 'list', 'test', 'data', 'python', 'file']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f'THE TOP 10 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a47cef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = LDA.transform(dtm)\n",
    "topic_results.argmax(axis=1)\n",
    "data['LDA'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9996487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "      <th>information</th>\n",
       "      <th>categoryEncoded</th>\n",
       "      <th>text</th>\n",
       "      <th>NMF</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34555135</td>\n",
       "      <td>Pandas: read_html</td>\n",
       "      <td>&lt;p&gt;I'm trying to extract US states from wiki U...</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;</td>\n",
       "      <td>1/1/2016 9:55</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Pandas: read_html &lt;p&gt;I'm trying to extract US ...</td>\n",
       "      <td>0</td>\n",
       "      <td>panda read html trying extract u state wiki ur...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34557209</td>\n",
       "      <td>How do I make a constructor for a derived class?</td>\n",
       "      <td>&lt;p&gt;I am trying to make a constructor for a der...</td>\n",
       "      <td>&lt;c++&gt;&lt;inheritance&gt;&lt;constructor&gt;&lt;derived-class&gt;</td>\n",
       "      <td>1/1/2016 14:58</td>\n",
       "      <td>LQ</td>\n",
       "      <td>How do I make a constructor for a derived clas...</td>\n",
       "      <td>1</td>\n",
       "      <td>make constructor derived class trying make con...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34557587</td>\n",
       "      <td>Re-exporting ES6 modules in TS 1.7?</td>\n",
       "      <td>&lt;p&gt;I'm getting a bit lost in TS re-exports. Sa...</td>\n",
       "      <td>&lt;typescript&gt;&lt;ecmascript-6&gt;&lt;es6-module-loader&gt;&lt;...</td>\n",
       "      <td>1/1/2016 15:50</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Re-exporting ES6 modules in TS 1.7? &lt;p&gt;I'm get...</td>\n",
       "      <td>0</td>\n",
       "      <td>exporting e module t getting bit lost t export...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34558264</td>\n",
       "      <td>Fetch API with Cookie</td>\n",
       "      <td>&lt;p&gt;I am trying out the new Fetch API but is ha...</td>\n",
       "      <td>&lt;cookies&gt;&lt;fetch-api&gt;</td>\n",
       "      <td>1/1/2016 17:21</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Fetch API with Cookie &lt;p&gt;I am trying out the n...</td>\n",
       "      <td>0</td>\n",
       "      <td>fetch api cookie trying new fetch api trouble ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34559136</td>\n",
       "      <td>Print list content in a given order</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;lt = ['7,777.7', '777.7', '77,777.7...</td>\n",
       "      <td>&lt;python&gt;&lt;list&gt;&lt;python-2.7&gt;&lt;for-loop&gt;</td>\n",
       "      <td>1/1/2016 19:08</td>\n",
       "      <td>LQ</td>\n",
       "      <td>Print list content in a given order &lt;pre&gt;&lt;code...</td>\n",
       "      <td>1</td>\n",
       "      <td>print list content given order lt proceed prin...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                             Title  \\\n",
       "0  34555135                                 Pandas: read_html   \n",
       "1  34557209  How do I make a constructor for a derived class?   \n",
       "2  34557587               Re-exporting ES6 modules in TS 1.7?   \n",
       "3  34558264                             Fetch API with Cookie   \n",
       "4  34559136               Print list content in a given order   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'm trying to extract US states from wiki U...   \n",
       "1  <p>I am trying to make a constructor for a der...   \n",
       "2  <p>I'm getting a bit lost in TS re-exports. Sa...   \n",
       "3  <p>I am trying out the new Fetch API but is ha...   \n",
       "4  <pre><code>lt = ['7,777.7', '777.7', '77,777.7...   \n",
       "\n",
       "                                                Tags    CreationDate   Y  \\\n",
       "0                                   <python><pandas>   1/1/2016 9:55  HQ   \n",
       "1     <c++><inheritance><constructor><derived-class>  1/1/2016 14:58  LQ   \n",
       "2  <typescript><ecmascript-6><es6-module-loader><...  1/1/2016 15:50  HQ   \n",
       "3                               <cookies><fetch-api>  1/1/2016 17:21  HQ   \n",
       "4               <python><list><python-2.7><for-loop>  1/1/2016 19:08  LQ   \n",
       "\n",
       "                                         information  categoryEncoded  \\\n",
       "0  Pandas: read_html <p>I'm trying to extract US ...                0   \n",
       "1  How do I make a constructor for a derived clas...                1   \n",
       "2  Re-exporting ES6 modules in TS 1.7? <p>I'm get...                0   \n",
       "3  Fetch API with Cookie <p>I am trying out the n...                0   \n",
       "4  Print list content in a given order <pre><code...                1   \n",
       "\n",
       "                                                text  NMF  LDA  \n",
       "0  panda read html trying extract u state wiki ur...    1    5  \n",
       "1  make constructor derived class trying make con...    2    2  \n",
       "2  exporting e module t getting bit lost t export...    1    3  \n",
       "3  fetch api cookie trying new fetch api trouble ...    1    0  \n",
       "4  print list content given order lt proceed prin...    5    5  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58413c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
